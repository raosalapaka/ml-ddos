{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reads the file filename in chunks of size provided by chunksize\n",
    "Parameters: filename: name of the data file\n",
    "            chunksize: number of rows read each time from file, default=200_000\n",
    "            low_memory: indicates if there is low_memory, default=False\n",
    "Returns the number of rows labeled as BENIGN (normal flow),\n",
    "            number of rows labeled as a DDoS attack\n",
    "            rows labeled as BENIGN and\n",
    "            rows identified as DDoS attacks\n",
    "'''\n",
    "def calculate_attack_type(filename, chunksize=200_000, low_memory=False):\n",
    "    num_benign = 0\n",
    "    num_attack = 0\n",
    "    attack_rows = []\n",
    "    benign_rows = []\n",
    "    with pd.read_csv(f'data/CICDDos2019/{filename}', chunksize=chunksize, low_memory=low_memory) as reader:\n",
    "        for chunk in reader:\n",
    "            benign_row = chunk.loc[chunk[' Label'] == 'BENIGN']\n",
    "            attack_row = chunk.loc[chunk[' Label'] != 'BENIGN']\n",
    "            num_benign += benign_row.shape[0]\n",
    "            num_attack += attack_row.shape[0]\n",
    "            attack_rows.append(attack_row)\n",
    "            benign_rows.append(benign_row)\n",
    "\n",
    "    return num_benign, num_attack, benign_rows, attack_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colors:\n",
    "    RESET = \"\\033[0m\"\n",
    "    BLACK = \"\\033[30m\"\n",
    "    RED = \"\\033[31m\"\n",
    "    GREEN = \"\\033[32m\"\n",
    "    YELLOW = \"\\033[33m\"\n",
    "    BLUE = \"\\033[34m\"\n",
    "    MAGENTA = \"\\033[35m\"\n",
    "    CYAN = \"\\033[36m\"\n",
    "    WHITE = \"\\033[37m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "    UNDERLINE = \"\\033[4m\"\n",
    "    BACKGROUND_RED = \"\\033[41m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: \u001b[1mDrDoS_LDAP.csv\u001b[0m, time(seconds): 10.7956719398       \n",
      "    benign:  1612                 proportion: 0.0007389269        \n",
      "    attack:  2179930              proportion: 0.9992610731        \n",
      "\n",
      "file: \u001b[1mDrDoS_NetBIOS.csv\u001b[0m, time(seconds): 19.2161002159       \n",
      "    benign:  1707                 proportion: 0.0004168512        \n",
      "    attack:  4093279              proportion: 0.9995831488        \n",
      "\n",
      "file: \u001b[1mDrDoS_SNMP.csv\u001b[0m, time(seconds): 24.8567929268       \n",
      "    benign:  1507                 proportion: 0.0002919763        \n",
      "    attack:  5159870              proportion: 0.9997080237        \n",
      "\n",
      "file: \u001b[1mDrDoS_UDP.csv\u001b[0m, time(seconds): 16.5517420769       \n",
      "    benign:  2157                 proportion: 0.0006876430        \n",
      "    attack:  3134645              proportion: 0.9993123570        \n",
      "\n",
      "file: \u001b[1mTFTP.csv\u001b[0m, time(seconds): 102.8893239498      \n",
      "    benign:  25247                proportion: 0.0012555807        \n",
      "    attack:  20082580             proportion: 0.9987444193        \n",
      "\n",
      "file: \u001b[1mDrDoS_DNS.csv\u001b[0m, time(seconds): 25.4846792221       \n",
      "    benign:  3402                 proportion: 0.0006704224        \n",
      "    attack:  5071011              proportion: 0.9993295776        \n",
      "\n",
      "file: \u001b[1mDrDoS_MSSQL.csv\u001b[0m, time(seconds): 21.9165740013       \n",
      "    benign:  2006                 proportion: 0.0004433641        \n",
      "    attack:  4522492              proportion: 0.9995566359        \n",
      "\n",
      "file: \u001b[1mDrDoS_NTP.csv\u001b[0m, time(seconds): 6.5658731461        \n",
      "    benign:  14365                proportion: 0.0118035476        \n",
      "    attack:  1202642              proportion: 0.9881964524        \n",
      "\n",
      "file: \u001b[1mDrDoS_SSDP.csv\u001b[0m, time(seconds): 13.6911177635       \n",
      "    benign:  763                  proportion: 0.0002921833        \n",
      "    attack:  2610611              proportion: 0.9997078167        \n",
      "\n",
      "file: \u001b[1mSyn.csv\u001b[0m, time(seconds): 7.5363891125        \n",
      "    benign:  392                  proportion: 0.0002476810        \n",
      "    attack:  1582289              proportion: 0.9997523190        \n",
      "\n",
      "file: \u001b[1mUDPLag.csv\u001b[0m, time(seconds): 1.7261240482        \n",
      "    benign:  3705                 proportion: 0.0099971668        \n",
      "    attack:  366900               proportion: 0.9900028332        \n",
      "\n",
      "\u001b[1m\u001b[31mAll Files, time(seconds)\u001b[0m: \u001b[1m\u001b[34m251.2303884029      \u001b[0m\n",
      "    \u001b[32mbenign\u001b[0m:  \u001b[1m\u001b[34m56863               \u001b[0m \u001b[32mproportion\u001b[0m:  \u001b[1m\u001b[34m0.0011358263        \u001b[0m\n",
      "    \u001b[32mattack\u001b[0m:  \u001b[1m\u001b[34m50006249            \u001b[0m \u001b[32mproportion\u001b[0m:  \u001b[1m\u001b[34m0.9988641737        \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Explore the datafiles generated by the CICDDoS2019 project. These files have millions of\n",
    "rows each identifying different classes of attacks from same features. \n",
    "Following does initial analysis on the proportion of rows labeled as BENIGN and DDoS flows\n",
    "Also creates dataframe lists capturing the rows in different attack files by separating them\n",
    "into attack_dflists representing the rows identified as DDoS attacks and the benign_dflists \n",
    "representing normal BENIGN traffic\n",
    "'''\n",
    "\n",
    "data_files = ['DrDoS_LDAP.csv',\n",
    "              'DrDoS_NetBIOS.csv',\n",
    "              'DrDoS_SNMP.csv',\n",
    "              'DrDoS_UDP.csv',\n",
    "              'TFTP.csv',\n",
    "              'DrDoS_DNS.csv',\n",
    "              'DrDoS_MSSQL.csv',\n",
    "              'DrDoS_NTP.csv',\n",
    "              'DrDoS_SSDP.csv',\n",
    "              'Syn.csv',\n",
    "              'UDPLag.csv']\n",
    "\n",
    "\n",
    "benign_allfiles = 0\n",
    "attack_allfiles = 0\n",
    "total_time = 0\n",
    "\n",
    "benign_dflist = []\n",
    "attack_dflist = []\n",
    "\n",
    "for data_file in data_files:\n",
    "    start_time = time.time()\n",
    "    benign, attack, benign_rows, attack_rows = calculate_attack_type(data_file)\n",
    "    end_time = time.time()\n",
    "    print(f'file: {Colors.BOLD}{data_file}{Colors.RESET}, time(seconds): {(end_time-start_time) :<20.10f}')\n",
    "    print(f'    benign:  {benign:<20} proportion: {benign/(benign+attack):<20.10f}')\n",
    "    print(f'    attack:  {attack:<20} proportion: {attack/(benign+attack):<20.10f}')\n",
    "    print()\n",
    "    benign_allfiles += benign\n",
    "    attack_allfiles  += attack\n",
    "    total_time += (end_time-start_time)    \n",
    "    \n",
    "    benign_dflist.append(benign_rows)\n",
    "    attack_dflist.append(attack_rows)\n",
    "\n",
    "print(f'{Colors.BOLD}{Colors.RED}All Files, time(seconds){Colors.RESET}: {Colors.BOLD}{Colors.BLUE}{total_time :<20.10f}{Colors.RESET}')\n",
    "\n",
    "print(f'    {Colors.GREEN}benign{Colors.RESET}:  {Colors.BOLD}\\\n",
    "{Colors.BLUE}{benign_allfiles:<20}{Colors.RESET} \\\n",
    "{Colors.GREEN}proportion{Colors.RESET}:  \\\n",
    "{Colors.BOLD}{Colors.BLUE}{benign_allfiles/(benign_allfiles+attack_allfiles) :<20.10f}{Colors.RESET}')\n",
    "\n",
    "print(f'    {Colors.GREEN}attack{Colors.RESET}:  {Colors.BOLD}\\\n",
    "{Colors.BLUE}{attack_allfiles:<20}{Colors.RESET} \\\n",
    "{Colors.GREEN}proportion{Colors.RESET}:  \\\n",
    "{Colors.BOLD}{Colors.BLUE}{attack_allfiles/(benign_allfiles+attack_allfiles) :<20.10f}{Colors.RESET}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper function to explore the number of rows collected in each\n",
    "dataframe for a specific file. Argument is a list of dataframe \n",
    "lists. For example dflists[0] is the list of dataframes capturing\n",
    "DrDoS_LDAP.csv\n",
    "'''\n",
    "\n",
    "def print_dflist(dflists):\n",
    "    for i, dflist in enumerate(dflists):\n",
    "        print(f'{data_files[i]:<18} \\\n",
    "        num_dfs: {len(dflists[i]):<5} \\\n",
    "        mean_num_rows: {round(np.mean([df_.shape[0] for df_ in dflists[i]])):<5} \\\n",
    "        total_rows: {np.sum([df_.shape[0] for df_ in dflists[i]]):<10}\\\n",
    "        select_per_df: {round(300_000/len(dflists[i]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper function to clean dflists. The column names for the datasets\n",
    "have leading/trailing white space which is not needed for our analysis\n",
    "'''\n",
    "def clean_dflist(dflists):\n",
    "    copy_dflist = []\n",
    "    clean_columns = [c.strip() for c in dflists[0][0].columns]\n",
    "    for dflist in dflists:\n",
    "        new_dflist = [pd.DataFrame(df) for df in dflist]\n",
    "        for df in new_dflist:\n",
    "            df.columns = clean_columns\n",
    "        copy_dflist.append(new_dflist)\n",
    "    return copy_dflist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the attack_dflist\n",
    "attack_dflist = clean_dflist(attack_dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_dflist[0][0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given the compute resources on local machine where analysis will be done, millions of rows with 80+\n",
    "features will be prohibitively cpu intensive. We will sample the data to decrease the number of rows\n",
    "to 300K (including both attack and benign rows)\n",
    "\n",
    "Following is a helper function that gets the sample size given the desired target number of rows and\n",
    "the dataframe list for a specific file. There is some math that needed to be done to compute the \n",
    "sample size to take care of the final dataframe that may not have enough rows\n",
    "'''\n",
    "\n",
    "def get_sample_size(dflist, target):\n",
    "    sample_size = target//len(dflist)\n",
    "    remaining = target - (sample_size * (len(dflist) - 1)) - min(sample_size, dflist[-1:][0].shape[0])\n",
    "    sample_size += remaining//(len(dflist) - 1)\n",
    "    return sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Samples the data frame list for a specific file\n",
    "chunk_sample_size if the sample to be taken from\n",
    "each data frame in the df list\n",
    "'''\n",
    "\n",
    "def sample_dflist(dflist, chunk_sample_size):\n",
    "    chunks = []\n",
    "    for df in dflist:\n",
    "        sample = df.sample(min(chunk_sample_size, df.shape[0]), \n",
    "                                random_state=42, \n",
    "                                axis=0, \n",
    "                                ignore_index=True)\n",
    "        chunks.append(sample)\n",
    "    return pd.concat(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following samples each attack file and collects them in  the sampled_attack_data\n",
    "# we sample ~250K attack rows as there are approximately 50_000 benign rows\n",
    "\n",
    "sampled_attack_data = []\n",
    "for dflist in attack_dflist:\n",
    "    sampled_attack_data.append(sample_dflist(dflist, \n",
    "                                            get_sample_size(dflist, 250_000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DrDoS_LDAP.csv: 249997\n",
      "DrDoS_NetBIOS.csv: 249984\n",
      "DrDoS_SNMP.csv: 249990\n",
      "DrDoS_UDP.csv: 250000\n",
      "TFTP.csv: 249975\n",
      "DrDoS_DNS.csv: 249990\n",
      "DrDoS_MSSQL.csv: 249987\n",
      "DrDoS_NTP.csv: 249995\n",
      "DrDoS_SSDP.csv: 249989\n",
      "Syn.csv: 250000\n",
      "UDPLag.csv: 250000\n"
     ]
    }
   ],
   "source": [
    "# print the various attack rows to make sure the sampling is correct\n",
    "\n",
    "for i, sample in enumerate(sampled_attack_data):\n",
    "    print(f'{data_files[i]}: {sample.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Following combines all dataframes in the dflists to one dataframe\n",
    "'''\n",
    "\n",
    "def concat_benign_data(dflists):\n",
    "    chunks = []\n",
    "    for dflist in dflists:\n",
    "        for df in dflist:\n",
    "            chunks.append(df)\n",
    "    return pd.concat(chunks)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all benign dataframe into one dataframe\n",
    "\n",
    "benign_dflist = clean_dflist(benign_dflist)\n",
    "benign_df = concat_benign_data(benign_dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((249997, 88),\n",
       " (83332, 88),\n",
       " (83332, 88),\n",
       " (83333, 88),\n",
       " (18954, 88),\n",
       " (18954, 88),\n",
       " (18955, 88))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sampled_attack_data[0]\n",
    "df_1, df_2, df_3 = df.iloc[0:df.shape[0]//3,:], df.iloc[df.shape[0]//3:2*df.shape[0]//3,:], df.iloc[2*df.shape[0]//3:,:]\n",
    "df.shape, df_1.shape, df_2.shape, df_3.shape, benign_df.iloc[0:benign_df.shape[0]//3,:].shape, benign_df.iloc[benign_df.shape[0]//3:2*benign_df.shape[0]//3,:].shape, benign_df.iloc[2*benign_df.shape[0]//3:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the sampled benign and attck dataframes into 3 equal samller dfs to overcome\n",
    "# git constraint on size of files. Save these smaller sampled data into 3 different\n",
    "# files for benign and each type of attack\n",
    "\n",
    "benign_1, benign_2, benign_3 = benign_df.iloc[0:benign_df.shape[0]//3,:], benign_df.iloc[benign_df.shape[0]//3:2*benign_df.shape[0]//3,:], benign_df.iloc[2*benign_df.shape[0]//3:,:]\n",
    "\n",
    "for i, df in enumerate(sampled_attack_data):\n",
    "    df_1, df_2, df_3 = df.iloc[0:df.shape[0]//3,:], df.iloc[df.shape[0]//3:2*df.shape[0]//3,:], df.iloc[2*df.shape[0]//3:,:]\n",
    "    df_1 = pd.concat([df_1, benign_1])\n",
    "    df_1.to_csv(f'data/CICDDos2019/sampled_data/sampled_{data_files[i].split('.')[0]}_1.csv', index=False)\n",
    "    df_2 = pd.concat([df_2, benign_2])\n",
    "    df_2.to_csv(f'data/CICDDos2019/sampled_data/sampled_{data_files[i].split('.')[0]}_2.csv', index=False)\n",
    "    df_3 = pd.concat([df_3, benign_3])\n",
    "    df_3.to_csv(f'data/CICDDos2019/sampled_data/sampled_{data_files[i].split('.')[0]}_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_df.to_csv(f'data/CICDDos2019/sampled_data/aggreggated_benign.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
